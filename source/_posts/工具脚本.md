---
title: kafka工具脚本解析
date: 2014-12-22 12:39:04
tags: [kafka, tools, 源码剖析]
categories:
  - [kafka, 运维, 工具脚本]
---



为了方便管理和使用， Kafka提供了很多管理脚本， Linux版本的管理脚本存放在$KAFKA_HOME/bin目录下。下面先来介绍常用脚本的功能。  

<!-- more -->

* kafka-run-class.sh脚本：很多脚本和工具类都依赖于kafka-run-class脚本， 其中的主要功能是设置CLASSPATH， 进行JMX的相关配置， 配置Log4j， 指定存放日志文件和索引文件位置， 检测JAVA_HOME环境变量， 进行JVM的相关配置， 决定是否后台启动等。  

* kafka-server-start脚本： 启动Kafka Server。
* kafka-server-stop脚本： 停止Kafka Stop。
* kafka-topics脚本： 负责Topic相关操作， 例如， 创建Topic， 查询Topic名称以及详细信息， 增加分区的数量并完成新增分区的副本等。
* kafka-preferred-replica-election脚本： 触发指定的分区进行“优先副本”选举， 这样可以让分区Leader副本在集群中分布得更均匀。
* kafka-reassign-partitions脚本： 主要有三个功能， 一是生成副本迁移的方案， 二是触发副本迁移操作， 即将迁移方案写入到ZooKeeper中， 从而触发PartitionsReassignedListener处理， 三是检测指定分区的副本迁移是否已完成。
* kafka-console-producer脚本： 控制台版本的生产者， 我们可以在控制台中输入消息的key和value，由此脚本封装成消息并发送给服务端。
* kafka-console-consumer脚本： 控制台版本的消费者， 我们可以通过参数指定订阅的Topic， 此脚本
  会从服务端拉取消息并输出到控制台。
* kafka-consumer-groups脚本： 有两个主要的功能， 一是查询当前所有Consumer Group， 二是获取指
  定Consumer Group的详细信息，三是删除某Consumer Group。
* DumpLogSegments： 可由kafka-run-class脚本运行， 主要负责解析输出指定的日志文件和索引文件中的内容， 另外还可以实现索引文件的验证。
* kafka-producer-perf-test脚本： 负责测试生产者的各项性能指标。
* kafka-consumer-perf-test脚本： 负责测试消费者的各项性能指标。
* kafka-mirror-maker脚本： 实现了数据在多个集群的同步， 可用于Kafka集群的镜像制作。  

## kafka-run-class.sh

作用：

* 设置jmx配置
* 设置log目录
* 设置log4j配置文件路径
* 是否开启远程调试
* 设置java路径
* 设置jvm内存
* 设置jvm的优化配置
* 设置classpath
* 后台或前台启动kafka

```shell
#!/bin/bash
# 检测参数并打印使用方法（略）

# 判断操作系统（略）

# 检测INCLUDE_TEST_JARS变量是否为空
if [ -z "$INCLUDE_TEST_JARS" ]; then
  INCLUDE_TEST_JARS=false
fi

# Exclude jars not necessary for running commands.
regex="(-(test|test-sources|src|scaladoc|javadoc)\.jar|jar.asc)$"
should_include_file() {
  if [ "$INCLUDE_TEST_JARS" = true ]; then
    return 0
  fi
  file=$1
  if [ -z "$(echo "$file" | egrep "$regex")" ] ; then
    return 0
  else
    return 1
  fi
}

# 获取脚本所在目录的上一层目录
base_dir=$(dirname $0)/..
# 检测并设置SCALA_VERSION、SCALA_BINARY_VERSION（略）
# 检测$base_dir下的多个目录，根据should_include_file函数设置CLASSPATH（略）

# jmx的相关设置
if [ -z "$KAFKA_JMX_OPTS" ]; then
  KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false "
fi

if [  $JMX_PORT ]; then
  KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT "
fi

# 指定存放日志文件的目录，在dockerfile中指定LOG_DIR为/cloud/log/kafka
if [ "x$LOG_DIR" = "x" ]; then
  LOG_DIR="$base_dir/logs"
fi

# 指定日志配置文件的路径，在kafka-server-start.sh中指定KAFKA_LOG4J_OPTS为-Dlog4j.configuration=file:/cloud/service/kafka/bin/../config/log4j.properties
if [ -z "$KAFKA_LOG4J_OPTS" ]; then
  # 如果为空，说明不是起服务，而是工具，使用工具对应的日志配置文件
  LOG4J_DIR="$base_dir/config/tools-log4j.properties"
  (( CYGWIN )) && LOG4J_DIR=$(cygpath --path --mixed "${LOG4J_DIR}")
  KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:${LOG4J_DIR}"
else
  # 创建日志文件目录
  if [ ! -d "$LOG_DIR" ]; then
    mkdir -p "$LOG_DIR"
  fi
fi

# KAFKA_LOG4J_OPTS最终为"-Dkafka.logs.dir=/cloud/log/kafka -Dlog4j.configuration=file:/cloud/service/kafka/bin/../config/log4j.properties"
KAFKA_LOG4J_OPTS="-Dkafka.logs.dir=$LOG_DIR $KAFKA_LOG4J_OPTS"

# 通用的jvm设置可以加在该变量中，function-common.sh中有用到，后面远程调试等也是加在该变量中
if [ -z "$KAFKA_OPTS" ]; then
  KAFKA_OPTS=""
fi

# 是否开启远程调试，如要开启，在前面加export KAFKA_DEBUG=xxx。export DEBUG_SUSPEND_FLAG=y（等待远程调试连上才启动）
if [ "x$KAFKA_DEBUG" != "x" ]; then

    # Use default ports
    DEFAULT_JAVA_DEBUG_PORT="5005"

    if [ -z "$JAVA_DEBUG_PORT" ]; then
        JAVA_DEBUG_PORT="$DEFAULT_JAVA_DEBUG_PORT"
    fi

    # Use the defaults if JAVA_DEBUG_OPTS was not set
    DEFAULT_JAVA_DEBUG_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=${DEBUG_SUSPEND_FLAG:-n},address=$JAVA_DEBUG_PORT"
    if [ -z "$JAVA_DEBUG_OPTS" ]; then
        JAVA_DEBUG_OPTS="$DEFAULT_JAVA_DEBUG_OPTS"
    fi

    echo "Enabling Java debug options: $JAVA_DEBUG_OPTS"
    KAFKA_OPTS="$JAVA_DEBUG_OPTS $KAFKA_OPTS"
fi

# 设置java路径
if [ -z "$JAVA_HOME" ]; then
  JAVA="java"
else
  JAVA="$JAVA_HOME/bin/java"
fi

# 设置jvm内存，在function-kafka.sh中指定为KAFKA_HEAP_OPTS
if [ -z "$KAFKA_HEAP_OPTS" ]; then
  KAFKA_HEAP_OPTS="-Xmx256M"
fi

# 设置jvm的一些优化配置
if [ -z "$KAFKA_JVM_PERFORMANCE_OPTS" ]; then
  KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true"
fi

# 如果命令为kafka-run-class.sh --version
for args in "$@" ; do
  if [ "$args" = "--version" ]; then
    exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "kafka.utils.VersionInfo"
  fi
done

# 处理参数name、loggc、daemon三个参数
while [ $# -gt 0 ]; do
  COMMAND=$1
  case $COMMAND in
    -name)
      DAEMON_NAME=$2
      CONSOLE_OUTPUT_FILE=$LOG_DIR/$DAEMON_NAME.out
      shift 2
      ;;
    -loggc)
      if [ -z "$KAFKA_GC_LOG_OPTS" ]; then
        GC_LOG_ENABLED="true"
      fi
      shift
      ;;
    -daemon)
      DAEMON_MODE="true"
      shift
      ;;
    *)
      break
      ;;
  esac
done

# 设置jvm GC的相关参数。
GC_FILE_SUFFIX='-gc.log'
GC_LOG_FILE_NAME=''
if [ "x$GC_LOG_ENABLED" = "xtrue" ]; then
  GC_LOG_FILE_NAME=$DAEMON_NAME$GC_FILE_SUFFIX
  JAVA_MAJOR_VERSION=$($JAVA -version 2>&1 | sed -E -n 's/.* version "([0-9]*).*$/\1/p')
  if [[ "$JAVA_MAJOR_VERSION" -ge "9" ]] ; then
    KAFKA_GC_LOG_OPTS="-Xlog:gc*:file=$LOG_DIR/$GC_LOG_FILE_NAME:time,tags:filecount=10,filesize=102400"
  else
    KAFKA_GC_LOG_OPTS="-Xloggc:$LOG_DIR/$GC_LOG_FILE_NAME -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M"
  fi
fi

CLASSPATH=${CLASSPATH#:}

# 根据$DAEMON_MODE的值， 决定是否后台启动
if [ "x$DAEMON_MODE" = "xtrue" ]; then
  nohup $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@" > "$CONSOLE_OUTPUT_FILE" 2>&1 < /dev/null &
else
  exec $JAVA $KAFKA_HEAP_OPTS $KAFKA_JVM_PERFORMANCE_OPTS $KAFKA_GC_LOG_OPTS $KAFKA_JMX_OPTS $KAFKA_LOG4J_OPTS -cp $CLASSPATH $KAFKA_OPTS "$@"
fi

```



## kafka-server-start.sh

kafka-server-start脚本通过kafka-run-class脚本调用Kafka类来启动Broker， 在调用kafka-run-class脚本之前会进行检测命令行参数、 设置log4j配置文件、 设置JVM内存参数等操作。  

```shell
# 检查参数个数，若没有则打印用法
if [ $# -lt 1 ];
then
        echo "USAGE: $0 [-daemon] server.properties [--override property=value]*"
        exit 1
fi
# 获取当前脚本所在路径
base_dir=$(dirname $0)

# 设置Log4j相关的环境变量
if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
fi

# 设置JVM的内存
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
fi

# 设置DAEMON_NAME为kafkaServer（该名字用于daemon模式下的输出文件名和gc文件名）；设置jvm GC相关参数
EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

#加载/cloud/service/kafka/config路径下的配置文件，用于加载新增配置文件core-site.xml
classpathmunge () {
        escaped=`echo $1 | sed -e 's:\*:\\\\*:g'`
        if ! echo ${CLASSPATH} | /bin/egrep -q "(^|:)${escaped}($|:)" ; then
           if [ "$2" = "before" ] ; then
              CLASSPATH=$1:${CLASSPATH}
           else
              CLASSPATH=${CLASSPATH}:$1
           fi
        fi
}
classpathmunge /cloud/service/kafka/config

# 检测第一个参数是否为-daemon
COMMAND=$1
case $COMMAND in
  -daemon)
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift # 左移参数列表，即删除-daemon参数
    ;;
  *)
    ;;
esac

# 调用kafka-run-class脚本
exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"

```

## kafka-server-stop.sh



## kafka-topics.sh（doing）

kafka-topics脚本主要负责Topic相关的操作。 它的具体实现是通过上面分析的kafka-run-class来直接调用
TopicCommand类， 并根据参数执行指定的功能。  

```shell
#!/bin/bash

exec $(dirname $0)/kafka-run-class.sh kafka.admin.TopicCommand "$@"
```

TopicCommand.main()方法是该脚本的入口函数， 其中会使用joptsimple命令行解释器解释传入的参数，之后按照参数执行指定的行为。  

```scala
    try {
      if(opts.options.has(opts.createOpt))
        createTopic(zkClient, opts)
      else if(opts.options.has(opts.alterOpt))
        alterTopic(zkClient, opts)
      else if(opts.options.has(opts.listOpt))
        listTopics(zkClient, opts)
      else if(opts.options.has(opts.describeOpt))
        describeTopic(zkClient, opts)
      else if(opts.options.has(opts.deleteOpt))
        deleteTopic(zkClient, opts)
    }
```

listTopics()方法和describeTopic()方法主要是从ZooKeeper中指定的路径查询Topic的信息，deleteTopic()方法主要负责将待删除的Topic名称写入到Zookeeper的“/admin/delete_topics”路径下， 这会触发DeleteTopicsListener将待删除Topic交由TopicDeletionManager处理。这3个方法逻辑比较简单，不再做单独的分析。下面来关注创建Topic和修改Topic的相关逻辑。  

### 创建topic

TopicCommand.createTopic()方法负责创建Topic， 其核心逻辑是确定新建Topic中有多少个分区以及每个分区中的副本如何分配， 这里支持使用“replica-assignment”参数手动分配， 也支持使用“partitions”参数和“replication-factor”参数指定分区个数和副本个数进行自动分配。 之后， 该方法会将副本的分配结果写入到ZooKeeper中 。

```scala
  def createTopic(zkClient: KafkaZkClient, opts: TopicCommandOptions) {
    val topic = opts.options.valueOf(opts.topicOpt) // 获取topic参数
    // 将config参数解析成Properties对象
    val configs = parseTopicConfigsToBeAdded(opts)
    // 读取if-not-exists参数
    val ifNotExists = opts.options.has(opts.ifNotExistsOpt)
    // 检测Topic名称是否包含“.”或“_”字符， 若包含则输出警告信息（略）
    if (Topic.hasCollisionChars(topic))
      println("WARNING: Due to limitations in metric names, topics with a period ('.') or underscore ('_') could collide. To avoid issues it is best to use either, but not both.")
    val adminZkClient = new AdminZkClient(zkClient)
    try {
      // 检测是否有replica-assignment参数
      if (opts.options.has(opts.replicaAssignmentOpt)) {
        // replica-assignment参数的格式类似： 0:1:2,3:4:5,6:7:8.其中指定了编号为
        // 0的分区
        // 有三个副本且分配在Broker0~2上， 编号为1的分区由三个副本且分配在Broker3~5上，
        // 后面类似。 这里将replica-assignment参数内容解析成Map[Int,Seq[Int]]格式，
        // 其key为分区的编号， value是其副本所分配的BrokerId
        val assignment = parseReplicaAssignment(opts.options.valueOf(opts.replicaAssignmentOpt))
        // 写入ZooKeeper中
        adminZkClient.createOrUpdateTopicPartitionAssignmentPathInZK(topic, assignment, configs, update = false)
      } else {
        // 如果进行副本自动分配， 则必须指定partitions参数和replication-factor参数
        CommandLineUtils.checkRequiredArgs(opts.parser, opts.options, opts.partitionsOpt, opts.replicationFactorOpt)
        // 获取partitions参数值和replication-factor参数值
        val partitions = opts.options.valueOf(opts.partitionsOpt).intValue
        val replicas = opts.options.valueOf(opts.replicationFactorOpt). intValue
        // 根据disable-rack-aware参数决定分配副本时是否考虑机架信息
        val rackAwareMode = if (opts.options.has(opts.disableRackAware))
          RackAwareMode.Disabled
        else
          RackAwareMode.Enforced
        // 自动分配副本， 并写入Zookeeper
        adminZkClient.createTopic(topic, partitions, replicas, configs, rackAwareMode)
      }
    } catch {
      case e: TopicExistsException => if (!ifNotExists) throw e
    }
  }
```

AdminUtils.createTopic()方法中实现了自动分配副本的功能， 首先从ZooKeeper中获取Broker的信息并封装成BrokerMetadata集合， BrokerMetadata中只包含BrokerId和rack（机架） 信息。 之后调用AdminUtils.assignReplicasToBrokers()方法， 它会根据上述Broker信息和命令参数进行自动分配， 其中对于不需要机架感知的分配调用AdminUtils. assignReplicasToBrokersRackUnaware()方法进行处理， 对于需要机架感知的分配调用AdminUtils. assignReplicasToBrokersRackAware()方法进行处理。 最后使用AdminUtils.createOrUpdateTopicPartitionAssignmentPathInZK()方法将分配结果写入到ZooKeeper中。 

assignReplicasToBrokersRackUnaware()方法的代码如下：  

```scala
  private def assignReplicasToBrokersRackUnaware(nPartitions: Int,
                                                 replicationFactor: Int,
                                                 brokerList:Seq[Int],
                                                 fixedStartIndex:Int,
                                                 startPartitionId: Int): Map[Int,Seq[Int]] = {
    val ret = mutable.Map[Int, Seq[Int]]() // 用于记录副本分配结果
    val brokerArray = brokerList.toArray
    // 选择起始Broker进行分配
    val startIndex = if (fixedStartIndex >= 0) fixedStartIndex else rand.nextInt(brokerArray.length)
    var currentPartitionId = math.max(0, startPartitionId) // 选择起始分区
    // nextReplicaShift指定了副本的间隔， 目的是为了更均匀地将副本分配到不同的Broker上
    var nextReplicaShift = if (fixedStartIndex >= 0) fixedStartIndex else rand.nextInt(brokerArray.length)
    for (_ <- 0 until nPartitions) {
      if (currentPartitionId > 0 && (currentPartitionId % brokerArray.length == 0))
        nextReplicaShift += 1 // 递增nextReplicaShift
      // 将“优先副本”分配到startIndex指定的Broker之上
      val firstReplicaIndex = (currentPartitionId + startIndex) % brokerArray. length
      // 记录“优先副本”的分配结果
      val replicaBuffer = mutable.ArrayBuffer(brokerArray(firstReplicaIndex))
      for (j <- 0 until replicationFactor - 1) // 分配当前分区的其他副本
        replicaBuffer += brokerArray(replicaIndex(firstReplicaIndex, nextReplicaShift, j, brokerArray.length))
      ret.put(currentPartitionId, replicaBuffer)
      currentPartitionId += 1 // 分配下一个分区
    } 
    ret
  }
```

下面通过一个示例对assignReplicasToBrokersRackUnaware()方法的分配过程进行详细说明， 假设集群中有5个broker， 10个分区0~9， 每个分区分配3个副本， 无机架信息， 并且fixedStartIndex和startPartitionId均
为-1， startIndex随机得到的值为2， nextReplicaShift随机得到的值为1。 首先分区0的“优先副本”分配的firstReplicaIndex为(0 + 2)%4=2，即分配到Broker2上， 分配其他副本通过replicaIndex()方法实现：  

```scala
  private def replicaIndex(firstReplicaIndex: Int, secondReplicaShift: Int, replicaIndex: Int, nBrokers: Int): Int = {
    // 注意，shift的取值范围为[1, nBrokers-1]，不会取到0，这样其它副本的index肯定和第1个副本不一样
    val shift = 1 + (secondReplicaShift + replicaIndex) % (nBrokers - 1)
    (firstReplicaIndex + shift) % nBrokers
  }
```

通过replicaIndex()方法计算， 分区0的第2个副本的index为(2 + 1 + (1 + 0) % 4) % 5 = 4，即分配到Broker4上， 第3个副本的index为(2 + 1 + (1 + 1) % 4) % 5 = 0， 即分配到Broker0上。后续其他分区的副本分配与此类似， 其中需要注意的是， Partition0~Partition4的副本分配分配结束后， 此时nextReplicaShift递增变为2。 分区0～9的分配结果如下图所示：  

|       | 副本1 | 副本2 | 副本3 |
| ----- | ----- | ----- | ----- |
| 分区0 | 2     | 4     | 0     |
| 分区1 | 3     | 0     | 1     |
| 分区2 | 4     | 1     | 2     |
| 分区3 | 0     | 2     | 3     |
| 分区4 | 1     | 3     | 4     |
| 分区5 | 2     | 0     | 1     |
| 分区6 | 3     | 1     | 2     |
| 分区7 | 4     | 2     | 3     |
| 分区8 | 0     | 3     | 4     |
| 分区9 | 1     | 4     | 0     |

副本分配3个目标：

* 副本均匀分布在所有的broker上面
* 相同分区的副本分布在不同的broker上面
* 如果broker有机架（rack）信息，将相同分区的不同副本分配到不同的机架上

为了实现上面的3个目标（不考虑rack），我们需要：

* 各个分区的第一个副本的分配是round-robin，从broker列表的随机一个位置开始（random）
* 各个分区余下的副本以一个递增的位移确定broker（从第2个副本开始，位移都是递增1；第1个和第2个副本的位移不确定，与nextReplicaShift有关，但肯定和第1个副本不同。）
* 当分区数是broker数的倍数时，nextReplicaShift递增1（确保了分区间分配不重复，如果没有这个，则上面的分区5和分区0、分区6和分区1、分区7和分区2、分区8和分区3、分区9和分区4的分配会一致）

只有broker配置了broker.rack参数且kafka-topics.sh的入参中不带--disable-rack-aware，分配策略才会考虑机架，不同机架上的分配策略待补充（todo）

### 修改topic

TopicCommand.alterTopic()方法负责修改Topic的分区数量、 副本的分配以及相关配置信息。 需要注意， 对于修改Topic配置项的逻辑已经转移到kafka-configs脚本中了， 不再推荐使用kafka-topics脚本完成该功能。alterTopic()方法的具体实现如下： 

```scala
def alterTopic(zkClient: KafkaZkClient, opts: TopicCommandOptions) {
  // 解析要修改的topic，并校验（略）
  topics.foreach { topic =>
    val configs = adminZkClient.fetchEntityConfig(ConfigType.Topic, topic)
    // 如果参数指定要修改配置项，则执行修改配置项逻辑（会打印warn日志，该方式已deprecated）（略）

    // 如果参数指定了分区个数，则进行分区相关的修改
    if(opts.options.has(opts.partitionsOpt)) {
      // 不允许修改内部topic __consumer_offsets
      if (topic == Topic.GROUP_METADATA_TOPIC_NAME) {
        throw new IllegalArgumentException("The number of partitions for the offsets topic cannot be changed.")
      }
      println("WARNING: If partitions are increased for a topic that has a key, the partition " +
        "logic or ordering of the messages will be affected")
      // 解析分区个数  --partitions
      val nPartitions = opts.options.valueOf(opts.partitionsOpt).intValue
      // 获取topic当前分配策略
      val existingAssignment = zkClient.getReplicaAssignmentForTopics(immutable.Set(topic)).map {
        case (topicPartition, replicas) => topicPartition.partition -> replicas
      }
      if (existingAssignment.isEmpty)
        throw new InvalidTopicException(s"The topic $topic does not exist")
      // 解析参数指定的分配策略  --replica-assignment （传入的是全量分配策略，最终会解析出增量分配策略newAssignment）
      val replicaAssignmentStr = opts.options.valueOf(opts.replicaAssignmentOpt)
      val newAssignment = Option(replicaAssignmentStr).filter(_.nonEmpty).map { replicaAssignmentString =>
        val startPartitionId = existingAssignment.size
        val partitionList = replicaAssignmentString.split(",").drop(startPartitionId)
        AdminUtils.parseReplicaAssignment(partitionList.mkString(","), startPartitionId)
      }
      val allBrokers = adminZkClient.getBrokerMetadatas()
      // 完成分区数量的增加以及副本分配
      adminZkClient.addPartitions(topic, existingAssignment, allBrokers, nPartitions, newAssignment)
      println("Adding partitions succeeded!")
    }
  }
}
```

 AdminUtils.addPartitions()方法会根据原有分区的分配情况确定副本个数， 根据是否指定replicaassignment参数决定新增分区是否进行自动副本分配， 最后将原有分区和新增的Partition的副本分配结果合并后写入ZooKeeper。

```scala
  def addPartitions(topic: String,
                    existingAssignment: Map[Int, Seq[Int]],
                    allBrokers: Seq[BrokerMetadata],
                    numPartitions: Int = 1,
                    replicaAssignment: Option[Map[Int, Seq[Int]]] = None,
                    validateOnly: Boolean = false): Map[Int, Seq[Int]] = {
    val existingAssignmentPartition0 = existingAssignment.getOrElse(0,
      throw new AdminOperationException(
        s"Unexpected existing replica assignment for topic '$topic', partition id 0 is missing. " +
          s"Assignment: $existingAssignment"))

    val partitionsToAdd = numPartitions - existingAssignment.size
    if (partitionsToAdd <= 0)
      throw new InvalidPartitionsException(
        s"The number of partitions for a topic can only be increased. " +
          s"Topic $topic currently has ${existingAssignment.size} partitions, " +
          s"$numPartitions would not be an increase.")
    // 校验新的分区分配方案中，副本个数是否和分区0的相同，副本id是否都是当前集群中的id
    replicaAssignment.foreach { proposedReplicaAssignment =>
      validateReplicaAssignment(proposedReplicaAssignment, existingAssignmentPartition0.size,
        allBrokers.map(_.id).toSet)
    }
    // 获取新的分区分配方案（如果没有则自动分配）
    val proposedAssignmentForNewPartitions = replicaAssignment.getOrElse {
      val startIndex = math.max(0, allBrokers.indexWhere(_.id >= existingAssignmentPartition0.head))
      // 自动分配逻辑，其中起始broker为第一个旧分区中分配broker的最大值，起始分区为第一个最新的分区
      AdminUtils.assignReplicasToBrokers(allBrokers, partitionsToAdd, existingAssignmentPartition0.size,
        startIndex, existingAssignment.size)
    }
    val proposedAssignment = existingAssignment ++ proposedAssignmentForNewPartitions
    if (!validateOnly) {
      info(s"Creating $partitionsToAdd partitions for '$topic' with the following replica assignment: " +
        s"$proposedAssignmentForNewPartitions.")
      // add the combined new list
      createOrUpdateTopicPartitionAssignmentPathInZK(topic, proposedAssignment, update = true)
    }
    proposedAssignment

  }
```



## kafka-preferred-replica-election.sh

```scala
#!/bin/bash
exec $(dirname $0)/kafka-run-class.sh kafka.admin.PreferredReplicaLeaderElectionCommand "$@"
```

PreferredReplicaLeaderElectionCommand负责将指定的分区写入zookeeper，这样PreferredReplicaElectionListener会监听ZooKeeper中的“/admin/preferred_replica_election”节点， 负责对指定的分区进行“优先副本”选举。  

这个脚本除了--zookeeper外只有一个--path-to-json-file参数，该参数指定一个JSON格式的输入文件， 在其中指定了需要进行“优先副本”选举的分区， 该JSON格式的输入文件示例如下：  

```json
{
	"partitions": [
        {
			"topic": "foo",
			"partition": 1
		},
		{
			"topic": "foobar",
			"partition": 2
		}
	]
}
```

如果未指定输入文件，则认为所有分区都需要进行优先副本选举操作。

首先来分析PreferredReplicaLeaderElectionCommand.main()方法， 它首先会检测path-to-json-file参数， 决定需要进行“优先副本”选举的分区集合， 之后会将该分区集合交给PreferredReplicaLeaderElectionCommand处理。  

```scala
  def main(args: Array[String]): Unit = {
    // 检测path-to-json-file参数和zookeeper参数（略）

    val zkConnect = options.valueOf(zkConnectOpt)
    var zkClient: KafkaZkClient = null
    try {
      val time = Time.SYSTEM
      zkClient = KafkaZkClient(zkConnect, JaasUtils.isZkSecurityEnabled, 30000, 30000, Int.MaxValue, time)
      // 获取需要进行“优先副本”选举的分区集合
      val partitionsForPreferredReplicaElection =
      // 未指定path-to-json-file参数则返回全部分区
        if (!options.has(jsonFileOpt))
          zkClient.getAllPartitions()
        else
        // 解析path-to-json-file参数指定的输入文件
          parsePreferredReplicaElectionData(Utils.readFileAsString(options.valueOf(jsonFileOpt)))
      // 创建preferredReplicaElectionCommand对象
      val preferredReplicaElectionCommand = new PreferredReplicaLeaderElectionCommand(zkClient, partitionsForPreferredReplicaElection)
      // 将指定的分区写入到ZooKeeper中的“/admin/preferred_replica_election”节点中
      preferredReplicaElectionCommand.moveLeaderToPreferredReplica()
    } catch {
      case e: Throwable =>
        println("Failed to start preferred replica election")
        println(Utils.stackTrace(e))
    } finally {
      if (zkClient != null)
        zkClient.close()
    }
  }
```

moveLeaderToPreferredReplica()方法首先会检测指定的Topic是否包含指定的分区， 之后会调用writePreferredReplicaElectionData()方法将需要进行“优先副本”选举的分区信息写入ZooKeeper。

操作示例：

```shell
// kafka多副本，当下线某个kafka后，leader副本会不均衡，执行该命令后会变均衡
sh kafka-preferred-replica-election.sh --zookeeper 192.168.223.233:2181/kafka
```

kafka逻辑中默认开启了leader副本的均衡，开关为auto.leader.rebalance.enable（默认true），周期为leader.imbalance.check.interval.seconds（默认300s），触发阈值为leader.imbalance.per.broker.percentage（默认10%，计算方法？）

PreferredReplicaElectionListener逻辑整理（todo）

## kafka-reassign-partition.sh

```shell
#!/bin/bash
exec $(dirname $0)/kafka-run-class.sh kafka.admin.ReassignPartitionsCommand "$@"
```

使用场景：todo

kafka-reassign-partitions脚本的主要功能有三个： 一是生成副本迁移的方案； 二是将副本迁移方案写入到ZooKeeper中， 由PartitionsReassignedListener处理； 三是检测指定分区的副本迁移是否完成。

ReassignPartitionsCommand.main()方法是kafka-reassign-partitions脚本的入口方法， 它会检测verify、generate、 execute三个参数并进入不同的处理流程。

```scala
  def main(args: Array[String]): Unit = {
    // 只能是verify、generate、 execute中的其中一个
    val opts = validateAndParseArgs(args)
    val zkConnect = opts.options.valueOf(opts.zkConnectOpt)
    val time = Time.SYSTEM
    val zkClient = KafkaZkClient(zkConnect, JaasUtils.isZkSecurityEnabled, 30000, 30000, Int.MaxValue, time)

    val adminClientOpt = createAdminClient(opts)

    try {
      if(opts.options.has(opts.verifyOpt))
        // 检测副本迁移是否结束
        verifyAssignment(zkClient, adminClientOpt, opts)
      else if(opts.options.has(opts.generateOpt))
        // 输出当前副本的分配情况，并生成副本迁移方案
        generateAssignment(zkClient, opts)
      else if (opts.options.has(opts.executeOpt))
        // 将副本迁移方案写入zk中
        executeAssignment(zkClient, adminClientOpt, opts)
    } catch {
      case e: Throwable =>
        println("Partitions reassignment failed due to " + e.getMessage)
        println(Utils.stackTrace(e))
    } finally zkClient.close()
  }
```

ReassignPartitionsCommand.generateAssignment()方法负责输出当前副本的分配情况，并生成副本迁移方案。它会读取topics-to-move-json-file参数和broker-list参数，然后调用AdminUtils.assignReplicasToBrokers()方法生成分配方案（该方法详见kafka-topics.sh节的介绍）。topics-to-move-json-file指定的文件的格式如下：

```json
{
	"topics": [{
		"topic": "foo"
	}, {
		"topic": "foo1"
	}],
	"version": 1
}
```

使用示例：

```shell
kafka-reassign-partitions.sh --zookeeper 192.168.223.233:2181/kafka --topics-to-move-json-file xxx.json --broker-list 0,1,2 --generate
```

输出：

```shell
Current partition replica assignment
{"version":1,"partitions":[{"topic":"test_2","partition":13,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":3,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":4,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":12,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":8,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":2,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":6,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":0,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":9,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":11,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":7,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":14,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":1,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":10,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":5,"replicas":[0,1],"log_dirs":["any","any"]}]}

Proposed partition reassignment configuration
{"version":1,"partitions":[{"topic":"test_2","partition":9,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":1,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":6,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":3,"replicas":[1,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":14,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":0,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":11,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":5,"replicas":[0,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":8,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":2,"replicas":[0,2],"log_dirs":["any","any"]},{"topic":"test_2","partition":13,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":10,"replicas":[2,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":7,"replicas":[2,1],"log_dirs":["any","any"]},{"topic":"test_2","partition":12,"replicas":[1,0],"log_dirs":["any","any"]},{"topic":"test_2","partition":4,"replicas":[2,0],"log_dirs":["any","any"]}]}
```

ReassignPartitionsCommand.executeAssignment()方法负责将副本迁移方案写入zk中，它会读取reassignment-json-file参数获得副本迁移方案，并将方案写入zk中。另外还会读取--throttle和--replica-alter-log-dirs-throttle，分别表示副本在broker间和broker内迁移的限流。

reassignment-json-file文件的示例为(即执行generate后的输出Proposed partition reassignment configuration)：

```json
{
	"partitions": [{
		"topic": "foo",
		"partition": 1,
		"replicas": [1, 2, 3],
		"log_dirs": ["dir1", "dir2", "dir3"]
	}],
	"version": 1
}
```

使用示例：

```shell
kafka-reassign-partitions.sh --zookeeper 192.168.223.233:2181/kafka --reassignment-json-file xxx1.json --execute
```

当迁移的目标信息写入到“/admin/reassign_partitions”路径后， 会触发PartitionsReassignedListener监听器(todo)。

ReassignPartitionsCommand.verifyAssignment()主要负责检测副本迁移操作是否已完成。 它首先读取并分析reassignment-json-file参数指定的输入文件内容， 之后调用checkIfReassignmentSucceeded()方法检测每个分区的迁移情况。  

使用示例：

```shell
kafka-reassign-partitions.sh --zookeeper 192.168.223.233:2181/kafka --reassignment-json-file xxx1.json --verify
```



## kafka-console-producer.sh 

kafka-console-producer脚本是一个简易的控制台版本的生产者， 可以通过在控制台中输入消息的key和value， 然后由此脚本生成请求将消息追加到Kafka服务端。  

脚本内容：

```shell
#!/bin/bash
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx512M"
fi
exec $(dirname $0)/kafka-run-class.sh kafka.tools.ConsoleProducer "$@"
```

ConsoleProducer.main()方法是kafka-console-producer脚本的入口函数， 代码如下：  

```

```

使用示例：

```shell
kafka-console-producer.sh --broker-list 192.168.149.254:9090 --topic test_1
```



## kafka-console-consumer.sh

使用示例：

```shell
kafka-console-consumer.sh --bootstrap-server 192.168.149.254:9090 --topic test_1
```

## kafka-consumer-groups.sh（todo）

kafka-consumer-groups脚本的主要功能有三个： 一是查询当前所有Consumer Group； 二是获取某Consumer Group的详细信息； 三是删除某Consumer Group。 注意， 旧版本Consumer中的Consumer Group相关信息保存在ZooKeeper中， 该脚本只能删除旧版本的Consumer Group； 新版本消费者的Consumer Group信息记录在Offsets Topic这个内部Topic中， 不能通过该脚本进行删除。 

```shell
#!/bin/bash
exec $(dirname $0)/kafka-run-class.sh kafka.admin.ConsumerGroupCommand "$@"
```

## DumpLogSegments（todo）

在kafka.tools包中还有一些其他工具类， 这些工具类在$KAFKA_HOME/bin目录下并没有对应的脚本，例如， DumpLogSegments、 JmxTool等。 管理人员可以通过前面描述的kafka-run-class脚本使用这些工具类。  

DumpLogSegments工具类的主要功能是将指定的日志文件和索引文件中的内容打印到控制台， 它还可以实现验证索引文件的功能。  

使用示例：

```shell
[root@hdp-kafka-hdp-kafka-0 bin]# kafka-run-class.sh kafka.tools.DumpLogSegments --files /cloud/data9/kafka/test_1-8/00000000000087945724.log --print-data-log
Dumping /cloud/data9/kafka/test_1-8/00000000000087945724.log
Starting offset: 87945724
offset: 87945724 position: 0 CreateTime: 1719995281542 isvalid: true keysize: -1 valuesize: 5 magic: 2 compresscodec: NONE producerId: -1 producerEpoch: -1 sequence: -1 isTransactional: false headerKeys: [] payload: hehe
```



## kafka-producer-perf-test.sh

kafka-producer-perf-test脚本主要负责测试生产者的各种性能指标， 底层通过调用ProducerPerformance实现。 从Kafka 0.9.0版本开始， 废弃了原有core模块中的kafka.tools.ProducerPerformance， 开始使用tools模块中的org.apache.kafka.tools. ProducerPerformance。

```shell
#!/bin/bash
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx512M"
fi
exec $(dirname $0)/kafka-run-class.sh org.apache.kafka.tools.ProducerPerformance "$@"
```

 ProducerPerformance.main()方法是kafka-producer-perf-test脚本的入口函数。  

```java
public static void main(String[] args) throws Exception {
		// 1 解析校验参数（略）
    	// 2 从文件中读取payloadByteList， --payloadFile参数指定文件路径 （略）
		// 3 设置校验生产者客户端参数（略）
		// 4 实例化生产者客户端
        KafkaProducer<byte[], byte[]> producer = new KafkaProducer<>(props);

        if (transactionsEnabled)
            producer.initTransactions();

        byte[] payload = null;
        Random random = new Random(0);
    	// 生成单条消息数据体（根据单条消息大小生成随机字节填充）
        if (recordSize != null) {
            payload = new byte[recordSize];
            for (int i = 0; i < payload.length; ++i)
                payload[i] = (byte) (random.nextInt(26) + 65);
        }
        ProducerRecord<byte[], byte[]> record;
        // 创建Stats对象，用于各个指标的统计，其中num-records参数指定产生消息个数。todo
        Stats stats = new Stats(numRecords, 5000);
        long startMs = System.currentTimeMillis();
    
		// 限流器
        ThroughputThrottler throttler = new ThroughputThrottler(throughput, startMs);

        int currentTransactionSize = 0;
        long transactionStartTime = 0;
        for (int i = 0; i < numRecords; i++) {
            if (transactionsEnabled && currentTransactionSize == 0) {
                producer.beginTransaction();
                transactionStartTime = System.currentTimeMillis();
            }

			// 生成单条消息数据体（如果指定了payloadFile，则以该文件中的随机一行作为消息数据体）
            if (payloadFilePath != null) {
                payload = payloadByteList.get(random.nextInt(payloadByteList.size()));
            }
            // 5 生成待发送的消息
            record = new ProducerRecord<>(topicName, payload);

            long sendStartMs = System.currentTimeMillis();
            // 6 消息发送成功后的回调函数（统计的相关工作）
            Callback cb = stats.nextCompletion(sendStartMs, payload.length, stats);
            // 7 发送消息
            producer.send(record, cb);

            currentTransactionSize++;
            if (transactionsEnabled && transactionDurationMs <= (sendStartMs - transactionStartTime)) {
                producer.commitTransaction();
                currentTransactionSize = 0;
            }

            if (throttler.shouldThrottle(i, sendStartMs)) {
                throttler.throttle();
            }
        }

        if (transactionsEnabled && currentTransactionSize != 0)
            producer.commitTransaction();

        // 打印相关（略）
    } catch (ArgumentParserException e) {
        if (args.length == 0) {
            parser.printHelp();
            Exit.exit(0);
        } else {
            parser.handleError(e);
            Exit.exit(1);
        }
    }

}
```

使用示例：

```shell
kafka-producer-perf-test.sh  --topic test_1 --num-records 100000000000000 --record-size 10240  --throughput 10000000 --producer-props bootstrap.servers=10.32.24.72:32095 --producer.config ./config/produce.properties

kafka-producer-perf-test.sh  --topic test_1 --num-records 100000000000000 --record-size 10240  --throughput 10000000 --producer-props bootstrap.servers=192.168.181.238:9090
```

参数说明：

```
throughput: 限制每秒最多多少条消息
num-records：生产多少条消息后结束
record-size：单条消息大小
producer-props：生产的服务端
```

Stats负责记录多项数据并在测试完成后输出测试的各项性能指标。 Stats中各个字段的含义如下所述。  

```
start： 记录开始测试时间戳。
reportingInterval： 两次输出之间的时间间隔，即时间窗口，5s。
sampling： 样本个数。 样本的个数与指定发送的消息数量有关， 默认是500000为一个样本。
sampling值为 (int) (numRecords / Math.min(numRecords, 500000));
latencies： 记录每个样本中的延迟。 
latencies是一个数组，值为 new int[(int) (numRecords / this.sampling) + 1];
iteration： 记录迭代次数， 与抽样有关。
count： 记录整个过程中发送的消息个数。
bytes： 记录发送消息的总字节数。
maxLatency： 记录从消息发出到对应响应返回之间的延迟的最大值。
totalLatency： 记录延迟的总时间。
windowCount： 当前时间窗口中发送消息的个数。
windowStart： 当前时间窗口的起始时间戳。
windowMaxLatency： 记录当前时间窗口中最大的延时。
windowTotalLatency： 记录当前时间窗口中延时的总时长。
windowBytes： 记录当前窗口发送的总字节数。
```

Stats.record()方法负责更新上述字段中的值， 并按照reportingInterval字段指定的时间间隔打印统计信息，  前4个值用于统计总的，在全部结束后打印。后4个值用于统计当前时间窗口的，每5s打印一次。

```java
        public void record(int iter, int latency, int bytes, long time) {
            this.count++; // 计算发送消息个数
            this.bytes += bytes; // 计算发送总字节数
            this.totalLatency += latency; // 计算总延迟
            this.maxLatency = Math.max(this.maxLatency, latency); // 记录最大延迟
            this.windowCount++; // 计算当前窗口发送消息个数
            this.windowBytes += bytes; // 计算当前窗口发送总字节数
            this.windowTotalLatency += latency; // 计算当前窗口的总延迟
            // 记录当前窗口的最大延迟
            this.windowMaxLatency = Math.max(windowMaxLatency, latency);
            // 选择样本， 更新latencies中对应值。通过采样记录确保latencies中最多有500000个记录
            if (iter % this.sampling == 0) { 
                this.latencies[index] = latency;
                this.index++;
            } 
            // 检测是否需要结束当前窗口， 并开启新窗口，5s一次
            if (time - windowStart >= reportingInterval) {
                printWindow(); // 输出当前窗口中记录的信息
                newWindow(); // 清空window字段， 开启下一个窗口的记录
            }
        }
```

在main()方法中， 发送的每一条消息都会创建一个对应的PerfCallback对象作为回调， 在PerfCallback.onCompletion()中会调用Stats.record()方法记录相关的统计信息。

```java
        public void onCompletion(RecordMetadata metadata, Exception exception) {
            long now = System.currentTimeMillis();
            int latency = (int) (now - start);
            this.stats.record(iteration, latency, bytes, now);
            if (exception != null)
                exception.printStackTrace();
        }
```



## kafka-consumer-perf-test.sh

kafka-consumer-perf-test脚本负责测试消费者的各项性能指标，底层通过调用ConsumerPerformance实现。

```shell
#!/bin/bash
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx512M"
fi
exec $(dirname $0)/kafka-run-class.sh kafka.tools.ConsumerPerformance "$@"

```

ConsumerPerformance.main()方法是kafka-consumer-perftest脚本的入口函数， main方法中逻辑很简单，不再赘述，主要是调用了consume()方法。下面详细看一下consume()方法。

```

```



使用示例：

```shell
kafka-consumer-perf-test.sh --topic test_1 --messages 10 --broker-list 192.168.149.254:9090 --show-detailed-stats

kafka-consumer-perf-test.sh --topic test_1 --broker-list 10.32.24.95:32096 --messages 1000000000000000 --group test_11 --timeout 1000000 client.id=clientA
```

参数说明：

```
--messages:需要消费的消息条数
--timeout：获取到消息之前最多等待的ms，默认是10000ms
--show-detailed-stats:每5s打印一次消费信息（包括每秒消息条数，每秒消费大小等）
```

## kafka-mirror-maker.sh（todo）